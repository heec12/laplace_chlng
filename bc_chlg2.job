#!/bin/bash
#SBATCH -p RM
#SBATCH -t 5:00:00
#SBATCH -N 1
#SBATCH --ntasks-per-node 25

module load cuda
module load mpi/pgi_openmpi

# echo commands to stdout
set -x

#mpicc laplace_MPI_test2.c -fast
#mpicc -mp -acc laplace_hybrd.c -fast
mpicc -acc laplace_hybrd.c -Minfo=accel -fast

# move to working directory
#cd $SCRATCH

# set variable so that task placement works as expected
export I_MPI_JOB_RESPECT_PROCESS_PLACEMENT=0

# copy input files to LOCAL file storage
#srun -N $SLURM_NNODES --ntasks-per-node=1 \
 #   sh -c 'cp $PROJECT/input.${SLURM_PROCID} $LOCAL'

# run MPI program
mpirun -np $SLURM_NTASKS ./a.out
#./a.out

# copy output files to persistent space/
#srun -N $SLURM_NNODES --ntasks-per-node=1 \ 
    #sh -c 'cp $LOCAL/output.* $PROJECT'

